---
title: "Análisis de datos Precios electricidad"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
  author: "Carlos Romero Matarin"
  html_document:
    df_print: paged
---

Programación realizada en lenguaje de programación Python y R, por Carlos Romero Matarin para el TFG de economía de la UAB

Importamos librerías necesarias para el tratamiento de datos de precios

```{python}
import numpy as np
import pandas as pd
import os
import json
```


Variables de ruta del ordenador para obtener los datos:

```{python}
ruta_precios_2019 = 'C:/Users/crome/Desktop/TFG_ECO/Precios_Electricidad/2019/'

ruta_climatica_2019 = 'C:/Users/crome/Desktop/TFG_ECO/datos_climaticos/'

ruta_Estructura_2019 = 'C:/Users/crome/Desktop/TFG_ECO/TFG_Entrega_Parcial_Carlos_Romero_1518680/estructura/estructura_2019.xlsx'

ruta_Demanda_2019 = 'C:/Users/crome/Desktop/TFG_ECO/TFG_Entrega_Parcial_Carlos_Romero_1518680/Demanda/demanda_2019.xlsx'


```


Analizamos los datos de 2019, obtenidos desde la página oficial de OMIE (Operador del mercado diario eléctrico)

https://www.omie.es/es/file-access-list?parents%5B0%5D=/&parents%5B1%5D=Mercado%20Diario&parents%5B2%5D=1.%20Precios&dir=Precios%20horarios%20del%20mercado%20diario%20en%20Espa%C3%B1a&realdir=marginalpdbc

Tratamiento de datos:

```{python}
#Analisis de datos 2019

# Importar todos los datos de diferentes archivos en una sola tabla 

ruta = ruta_precios_2019

#numero total de archivos dentro de la carpeta
num_archivos = len(os.listdir(ruta))

#lista de todos los archivos dentro de la carpeta
lista_archivos = os.listdir(ruta)

#recorrer todos los archivos y guardarlos en una lista
lista_datos = []
for i in range(num_archivos):
    archivo = lista_archivos[i]

    #leer el archivo y guardar los datos en un dataframe
    datos = pd.read_csv(ruta + '/' + archivo, sep = ';', decimal = '.')

    lista_datos.append(datos)

#concatenar todos los archivos en un solo dataframe
datos = pd.concat(lista_datos)

#Eliminar filas con nada en la primera columna con indice 0
datos = datos.dropna(subset = [datos.columns[0]])

#Eliminar ultima columna
datos = datos.drop(datos.columns[-1], axis = 1)

#pasar a csv
datos.to_csv('2019.csv', sep = ';', decimal = '.')

# Importar datos de 2019
datos = pd.read_csv('2019.csv', sep = ';', decimal = '.')

#renombrar columnas
datos = datos.rename(columns = {'Unnamed: 0': 'Año', 'Unnamed: 1': 'Mes', 'Unnamed: 2': 'Dia', 'Unnamed: 3': 'Hora', 'Unnamed: 4': 'Precio'})

#eliminar ultima columna
datos = datos.drop(datos.columns[-1], axis = 1)

#datos de dolumas año, mes, dia y hora de decimal a entero
datos['Año'] = datos['Año'].astype(int)
datos['Mes'] = datos['Mes'].astype(int)
datos['Dia'] = datos['Dia'].astype(int)
datos['Hora'] = datos['Hora'].astype(int)

#eliminar columnas que hora
datos = datos.drop(datos.columns[3], axis = 1)

#agrupar por año, mes y dia
datos = datos.groupby(['Año', 'Mes', 'Dia']).mean()

#pasar a csv pepe.csv
datos.to_csv('datos_Media_Diario.csv', sep = ';', decimal = '.')

datos = pd.read_csv('datos_Media_Diario.csv', sep = ';', decimal = '.')
```

Traemos datos climáticos desde la web oficinal de AEMET, los datos han sido descargados por medio de la API que se puede obtener en la web, para realizar más rápido los cálculos hemos descargado los datos en una carpeta con archivos del tipo .json, los datos desde la API viene en formato aray json.

Tratamiento de datos:

```{python}
#datos de barcelona
with open(ruta_climatica_2019+'datosBarcelona.json') as file:
    datosJsonBarcelona = json.load(file)

#convertir array json a dataframe
#{'fecha': '2019-01-01', 'indicativo': '0201D', 'nombre': 'BARCELONA', 
# 'provincia': 'BARCELONA', 'altitud': '6', 'tmed': '11,4', 
# 'prec': '0,0', 'tmin': '6,6', 'horatmin': '03:40', 'tmax': '16,2', 
# 'horatmax': '12:30', 'dir': '01', 'velmedia': '3,1', 'racha': '6,4', 
# 'horaracha': '07:30'}
dfBarcelona = pd.DataFrame(datosJsonBarcelona)

#datos de madrid
with open(ruta_climatica_2019+'datosMadrid.json') as file:
    datosJsonMadrid = json.load(file)

#convertir array json a dataframe
dfMadrid = pd.DataFrame(datosJsonMadrid)

#datos de sevilla
with open(ruta_climatica_2019+'datosSevilla.json') as file:
    datosJsonSevilla = json.load(file)

#convertir array json a dataframe
dfSevilla = pd.DataFrame(datosJsonSevilla)

#datos de a coruña
with open(ruta_climatica_2019+'datosCoruna.json') as file:
    datosJsonCoruna = json.load(file)

#convertir array json a dataframe
dfCoruna = pd.DataFrame(datosJsonCoruna)

#datos de navarra
with open(ruta_climatica_2019+'datosNavarra.json') as file:
    datosJsonNavarra = json.load(file)

#convertir array json a dataframe
dfNavarra = pd.DataFrame(datosJsonNavarra)

#unir los dataframes en uno solo
df = pd.concat([dfBarcelona, dfMadrid, dfSevilla, dfCoruna, dfNavarra], ignore_index=True)

#eliminar columnas que no se van a utilizar
df = df.drop(['indicativo', 'altitud', 'horatmin', 'horatmax', 'dir', 'velmedia', 'racha', 'horaracha','presMax', 'horaPresMax','presMin','horaPresMin','sol'], axis=1)


#diferentes valores que puede tomar la columna prec
#print(df['prec'].unique())
# ['Ip' 'Acum' '9,9' '9,8' '9,6' '9,5' '9,4' '9,3' '9,1' '9,0' '80,9' '8,8'
#  '8,6' '8,5' '8,4' '8,2' '8,0' '7,8' '7,7' '7,6' '7,4' '7,3' '7,2' '7,0'
#  '6,8' '6,7' '6,6' '6,4' '6,3' '6,2' '6,1' '6,0' '58,3' '53,2' '50,0'
#  '5,9' '5,8' '5,7' '5,6' '5,4' '5,3' '5,2' '5,1' '48,6' '47,2' '42,2'
#  '42,0' '4,8' '4,7' '4,6' '4,4' '4,3' '4,2' '4,1' '4,0' '39,1' '38,5'
#  '38,4' '36,7' '36,6' '34,4' '32,4' '3,9' '3,8' '3,6' '3,5' '3,4' '3,3'
#  '3,2' '3,1' '3,0' '29,7' '29,6' '28,5' '28,2' '27,6' '27,3' '27,2' '26,9'
#  '26,8' '26,4' '25,6' '25,2' '24,9' '24,8' '24,0' '23,8' '23,2' '23,0'
#  '22,8' '22,6' '21,8' '21,6' '20,6' '20,0' '2,9' '2,8' '2,7' '2,6' '2,5'
#  '2,4' '2,3' '2,2' '2,1' '2,0' '18,6' '18,4' '18,3' '18,2' '18,1' '18,0'
#  '17,9' '17,8' '17,4' '17,3' '17,2' '17,0' '16,9' '16,8' '16,2' '15,8'
#  '15,6' '15,2' '15,0' '14,9' '14,6' '14,4' '13,9' '13,7' '13,4' '13,2'
#  '12,9' '12,8' '12,6' '12,4' '12,1' '12,0' '11,8' '11,6' '11,2' '11,1'
#  '10,9' '10,8' '10,6' '10,4' '10,2' '10,1' '10,0' '1,9' '1,8' '1,7' '1,6'
#  '1,5' '1,4' '1,3' '1,2' '1,1' '1,0' '0,9' '0,8' '0,7' '0,6' '0,5' '0,4'
#  '0,3' '0,2' '0,1' '0,0' nan]

#Convertir datos de la columna prec (ip, acum) a nan
df['prec'] = df['prec'].replace(['Ip', 'Acum'], np.nan)

#convertir , por . en los datos de la columna prec
df['prec'] = df['prec'].str.replace(',','.')

#convertir datos de la columna prec a float
df['prec'] = df['prec'].astype(float)

#convertir , por . en los datos de la columna tmin
df['tmin'] = df['tmin'].str.replace(',','.')

#convertir datos de la columna tmin a float
df['tmin'] = df['tmin'].astype(float)

#convertir , por . en los datos de la columna tmax
df['tmax'] = df['tmax'].str.replace(',','.')

#convertir datos de la columna tmax a float
df['tmax'] = df['tmax'].astype(float)

#convertir , por . en los datos de la columna tmed
df['tmed'] = df['tmed'].str.replace(',','.')

#convertir datos de la columna tmed a float
df['tmed'] = df['tmed'].astype(float)

#valores nan de la columna prec a la media de la columna
df['prec'] = df['prec'].fillna(df['prec'].mean())

#valores nan de la columna tmin a la media de la columna
df['tmin'] = df['tmin'].fillna(df['tmin'].mean())

#valores nan de la columna tmax a la media de la columna
df['tmax'] = df['tmax'].fillna(df['tmax'].mean())

#valores nan de la columna tmed a la media de la columna
df['tmed'] = df['tmed'].fillna(df['tmed'].mean())

#convertir datos de la columna fecha a datetime
df['fecha'] = pd.to_datetime(df['fecha'], format='%Y-%m-%d')

#convertir datos de la columna fecha a datetime
df['fecha'] = pd.to_datetime(df['fecha'], format='%Y-%m-%d')

#agrupar por fecha y calcular la media de los datos
df = df.groupby('fecha').mean()

#separar la columna fecha en dia, mes y año
df['Dia'] = df.index.day
df['Mes'] = df.index.month
df['Año'] = df.index.year

#convertir datos de la columna dia a int
df['Dia'] = df['Dia'].astype(int)

#convertir datos de la columna mes a int
df['Mes'] = df['Mes'].astype(int)

#convertir datos de la columna año a int
df['Año'] = df['Año'].astype(int)

DatosMeteorologicos = df
```

Traemos datos de estructura de la generación eléctrica diaria, estos datos están en formato csv

Tratamiento de datos:
```{python}

#Lectura del fichero excel
df_Estructura_2019 = pd.read_excel(ruta_Estructura_2019)

# pasar filas a columnas
df_Estructura_2019 = df_Estructura_2019.transpose()

#primera fila y primera columna poner fecha
df_Estructura_2019.iloc[0,0] = 'Fecha'

#primera fila como cabecera
new_header = df_Estructura_2019.iloc[0] #
df_Estructura_2019 = df_Estructura_2019[1:]
df_Estructura_2019.columns = new_header

# sacar fecha de la primera columna y dividirla en año, mes y dia, la fecha esta en 01/ene/19
df_Estructura_2019['Año'] = df_Estructura_2019['Fecha'].str.split('/').str[2]
df_Estructura_2019['Mes'] = df_Estructura_2019['Fecha'].str.split('/').str[1]
df_Estructura_2019['Dia'] = df_Estructura_2019['Fecha'].str.split('/').str[0]

#convertir a entero
df_Estructura_2019['Año'] = df_Estructura_2019['Año'].astype(int)
df_Estructura_2019['Dia'] = df_Estructura_2019['Dia'].astype(int)

# pasar de mes ene, feb, mar, etc a numero
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['ene'], 1)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['feb'], 2)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['mar'], 3)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['abr'], 4)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['may'], 5)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['jun'], 6)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['jul'], 7)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['ago'], 8)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['sep'], 9)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['oct'], 10)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['nov'], 11)
df_Estructura_2019['Mes'] = df_Estructura_2019['Mes'].replace(['dic'], 12)

#año en formato YYYY no YY
df_Estructura_2019['Año'] = df_Estructura_2019['Año'] + 2000

#borrar columna fecha
df_Estructura_2019 = df_Estructura_2019.drop(['Fecha'], axis=1)

#valors nulos a 0
df_Estructura_2019 = df_Estructura_2019.fillna(0)

#renplazar - por 0
df_Estructura_2019 = df_Estructura_2019.replace('-', 0)

#convertir a float los valores de todas las columnas 

#primero reemplazar , por . para poder convertir a float
df_Estructura_2019['Hidráulica'] = df_Estructura_2019['Hidráulica'].str.replace(',', '.')
df_Estructura_2019['Turbinación bombeo'] = df_Estructura_2019['Turbinación bombeo'].str.replace(',', '.')
df_Estructura_2019['Nuclear'] = df_Estructura_2019['Nuclear'].str.replace(',', '.')
df_Estructura_2019['Carbón'] = df_Estructura_2019['Carbón'].str.replace(',', '.')
df_Estructura_2019['Fuel + Gas'] = df_Estructura_2019['Fuel + Gas'].str.replace(',', '.')
df_Estructura_2019['Motores diésel'] = df_Estructura_2019['Motores diésel'].str.replace(',', '.')
df_Estructura_2019['Turbina de gas'] = df_Estructura_2019['Turbina de gas'].str.replace(',', '.')
df_Estructura_2019['Turbina de vapor'] = df_Estructura_2019['Turbina de vapor'].str.replace(',', '.')
df_Estructura_2019['Ciclo combinado'] = df_Estructura_2019['Ciclo combinado'].str.replace(',', '.')
df_Estructura_2019['Hidroeólica'] = df_Estructura_2019['Hidroeólica'].str.replace(',', '.')
df_Estructura_2019['Eólica'] = df_Estructura_2019['Eólica'].str.replace(',', '.')
df_Estructura_2019['Solar fotovoltaica'] = df_Estructura_2019['Solar fotovoltaica'].str.replace(',', '.')
df_Estructura_2019['Solar térmica'] = df_Estructura_2019['Solar térmica'].str.replace(',', '.')
df_Estructura_2019['Otras renovables'] = df_Estructura_2019['Otras renovables'].str.replace(',', '.')
df_Estructura_2019['Cogeneración'] = df_Estructura_2019['Cogeneración'].str.replace(',', '.')
df_Estructura_2019['Residuos no renovables'] = df_Estructura_2019['Residuos no renovables'].str.replace(',', '.')
df_Estructura_2019['Residuos renovables'] = df_Estructura_2019['Residuos renovables'].str.replace(',', '.')
df_Estructura_2019['Generación total'] = df_Estructura_2019['Generación total'].str.replace(',', '.')

#convertir a float
df_Estructura_2019['Hidráulica'] = df_Estructura_2019['Hidráulica'].astype(float)
df_Estructura_2019['Turbinación bombeo'] = df_Estructura_2019['Turbinación bombeo'].astype(float)
df_Estructura_2019['Nuclear'] = df_Estructura_2019['Nuclear'].astype(float)
df_Estructura_2019['Carbón'] = df_Estructura_2019['Carbón'].astype(float)
df_Estructura_2019['Fuel + Gas'] = df_Estructura_2019['Fuel + Gas'].astype(float)
df_Estructura_2019['Motores diésel'] = df_Estructura_2019['Motores diésel'].astype(float)
df_Estructura_2019['Turbina de gas'] = df_Estructura_2019['Turbina de gas'].astype(float)
df_Estructura_2019['Turbina de vapor'] = df_Estructura_2019['Turbina de vapor'].astype(float)
df_Estructura_2019['Ciclo combinado'] = df_Estructura_2019['Ciclo combinado'].astype(float)
df_Estructura_2019['Hidroeólica'] = df_Estructura_2019['Hidroeólica'].astype(float)
df_Estructura_2019['Eólica'] = df_Estructura_2019['Eólica'].astype(float)
df_Estructura_2019['Solar fotovoltaica'] = df_Estructura_2019['Solar fotovoltaica'].astype(float)
df_Estructura_2019['Solar térmica'] = df_Estructura_2019['Solar térmica'].astype(float)
df_Estructura_2019['Otras renovables'] = df_Estructura_2019['Otras renovables'].astype(float)
df_Estructura_2019['Cogeneración'] = df_Estructura_2019['Cogeneración'].astype(float)
df_Estructura_2019['Residuos no renovables'] = df_Estructura_2019['Residuos no renovables'].astype(float)
df_Estructura_2019['Residuos renovables'] = df_Estructura_2019['Residuos renovables'].astype(float)
df_Estructura_2019['Generación total'] = df_Estructura_2019['Generación total'].astype(float)

#valores nulos a 0
df_Estructura_2019 = df_Estructura_2019.fillna(0)

DatosEstructura = df_Estructura_2019
```

Traemos datos de la demanda eléctrica diaria, estos datos están en formato csv

Tratamiento de datos:
```{python}
#Lectura del fichero excel
df_Demanda_2019 = pd.read_excel(ruta_Demanda_2019)

#    Column1     Column2     Column3     Column4     Column5     Column6  ...   Column361          Column362   Column363          Column364   Column365          Column366
# 0            01/ene/19   02/ene/19   03/ene/19   04/ene/19   05/ene/19  ...   26/dic/19          27/dic/19   28/dic/19          29/dic/19   30/dic/19          31/dic/19
# 1  Demanda  582,949806  742,199407  787,764963 

#Eliminacion de la primera columna
df_Demanda_2019 = df_Demanda_2019.drop(df_Demanda_2019.columns[0], axis = 1)

#convertir columanas en filas
df_Demanda_2019 = df_Demanda_2019.transpose()

#renombrar columnas, columna 1 es la fecha y columna 2 es la demanda
df_Demanda_2019 = df_Demanda_2019.rename(columns = {0: 'Fecha', 1: 'Demanda'})

# sacar fecha de la primera columna y dividirla en año, mes y dia, la fecha esta en 01/ene/19
df_Demanda_2019['Año'] = df_Demanda_2019['Fecha'].str.split('/').str[2]
df_Demanda_2019['Mes'] = df_Demanda_2019['Fecha'].str.split('/').str[1]
df_Demanda_2019['Dia'] = df_Demanda_2019['Fecha'].str.split('/').str[0]

# convertir a entero
df_Demanda_2019['Año'] = df_Demanda_2019['Año'].astype(int)
df_Demanda_2019['Dia'] = df_Demanda_2019['Dia'].astype(int)

# pasar de mes ene, feb, mar, etc a numero
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['ene'], 1)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['feb'], 2)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['mar'], 3)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['abr'], 4)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['may'], 5)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['jun'], 6)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['jul'], 7)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['ago'], 8)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['sep'], 9)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['oct'], 10)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['nov'], 11)
df_Demanda_2019['Mes'] = df_Demanda_2019['Mes'].replace(['dic'], 12)

#año en formato YYYY no YY
df_Demanda_2019['Año'] = df_Demanda_2019['Año'] + 2000

#pasar demanda de string a float
df_Demanda_2019['Demanda'] = df_Demanda_2019['Demanda'].str.replace(',', '.')
df_Demanda_2019['Demanda'] = df_Demanda_2019['Demanda'].astype(float)

#eliminar columna fecha
df_Demanda_2019 = df_Demanda_2019.drop(['Fecha'], axis = 1)

DatosDemanda = df_Demanda_2019
```


Unimos los dos datos por los datos comunes Año, Mes, Día:

```{python}
#Unir los datos de los precios con los datos de la meteorologia
datos = pd.merge(datos, DatosMeteorologicos, on = ['Año', 'Mes', 'Dia'])

#poner columna precio como ultima columna
precio = datos['Precio']
datos = datos.drop(['Precio'], axis = 1)
datos['Precio'] = precio

#pasar a csv
datos.to_csv('datos_Media_Diario_Climatico.csv', sep = ';', decimal = '.')

#leer datos
datos = pd.read_csv('datos_Media_Diario_Climatico.csv', sep = ';', decimal = '.')

#Unir los datros de los precios con los datos de la demanda
datos = pd.merge(datos, DatosDemanda, on = ['Año', 'Mes', 'Dia'])

#poner columna precio como ultima columna
precio = datos['Precio']
datos = datos.drop(['Precio'], axis = 1)
datos['Precio'] = precio

#pasar a csv
datos.to_csv('datos_Media_Diario_Climatico_Demanda.csv', sep = ';', decimal = '.')
datos = pd.read_csv('datos_Media_Diario_Climatico_Demanda.csv', sep = ';', decimal = '.')

#Unir los datos de los precios con los datos de la estructura
datos = pd.merge(datos, DatosEstructura, on = ['Año', 'Mes', 'Dia'])

#poner columna precio como ultima columna
precio = datos['Precio']
datos = datos.drop(['Precio'], axis = 1)
datos['Precio'] = precio

#pasar a csv
datos.to_csv('datos_Media_Diario_Climatico_Demanda_Estructura.csv', sep = ';', decimal = '.')
datos = pd.read_csv('datos_Media_Diario_Climatico_Demanda_Estructura.csv', sep = ';', decimal = '.')

#ELIMINAR COLUMNAS QUE NO SE VAN A USAR, las tres primeras
datos = datos.drop(datos.columns[0], axis = 1)
datos = datos.drop(datos.columns[0], axis = 1)
datos = datos.drop(datos.columns[0], axis = 1)

#pasar a csv
datos.to_csv('datos_Media_Diario_Climatico_Demanda_Estructura.csv', sep = ';', decimal = '.')

#Datos finales
datos = pd.read_csv('datos_Media_Diario_Climatico_Demanda_Estructura.csv', sep = ';', decimal = '.')


print(datos)
```

Obtenida la tabla principal de estudio donde tenemos los datos:

  -Año
  -Mes
  -Día
  -tmed: temperatura media
  -tmin: temperatura mínima
  -tmax: temperatura máxima
  -prec: precipitaciones
  -Demanda
  -...
  -Diferentes Tipos de generación energía (eólica, ...)
  -...
  -Generación total
  -Precio: precio diario (la media de todos los precios horarios     del día)

Podemos empezar el análisis de la regresión lineal:

```{python}
#Modelo de regresion lineal
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import statsmodels.api as sm


#separar datos de entrenamiento y de prueba por el 80% y 20%
X = datos.iloc[:, :-1].values

#datos de la columna precio es la utlima columna
y = datos.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

#entrenar el modelo
regressor = LinearRegression()
regressor.fit(X_train, y_train)

#predecir los resultados
y_pred = regressor.predict(X_test)

#comparar los resultados
df = pd.DataFrame({'Real': y_test, 'Prediccion': y_pred})
print(df)

print('Resultado del modelo de regresion lineal')
#Error cuadratico medio
from sklearn import metrics
print('Error cuadratico medio:', metrics.mean_squared_error(y_test, y_pred))

# Calcular el R^2
r2 = regressor.score(X_test, y_test)
# Imprimir el R^2
print('Coeficiente de determinación R^2:', r2)

#Imprimir coeficientes
print('Coeficientes: ', regressor.coef_)
#Imprimir intercepto
print('Intercepto: ', regressor.intercept_)
#Imprimir ecuacion de la recta
print('Ecuacion de la recta en forma matricial: y= ', regressor.coef_, 'x +', regressor.intercept_)

# Añadir una constante a las variables independientes
X2 = sm.add_constant(X_train)

# Crear un nuevo modelo con statsmodels
model = sm.OLS(y_train, X2)

# Ajustar el modelo
results = model.fit()

# Imprimir el resumen del modelo
print(results.summary())

#Grafica de predicciones
import matplotlib.pyplot as plt

# Crear una figura
plt.figure(figsize=(10,6))

# Crear un gráfico de línea con los datos reales
plt.plot(range(len(y_test)), y_test, color = 'red', label = 'Real')

# Crear un gráfico de línea con las predicciones
plt.plot(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicción')

# Añadir títulos y etiquetas
plt.title('Comparación de los valores reales y las predicciones')
plt.xlabel('Índice')
plt.ylabel('Precio')
plt.legend()

# Mostrar la gráfica
plt.show()

```

Estudio de la regresión polinomial

```{python}
#Modelo de regresion polinomial
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score


#separar datos de entrenamiento y de prueba por el 80% y 20%
X = datos.iloc[:, :-1].values

#datos de la columna precio es la utlima columna
y = datos.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

#entrenar el modelo
poly_reg = PolynomialFeatures(degree = 2)
X_poly = poly_reg.fit_transform(X_train)
regressor = LinearRegression()
regressor.fit(X_poly, y_train)

#predecir los resultados
y_pred = regressor.predict(poly_reg.fit_transform(X_test))

#comparar los resultados
df = pd.DataFrame({'Real': y_test, 'Prediccion': y_pred})
print(df)

print('Resultados de la regresion polinomial')
#Error cuadratico medio
from sklearn import metrics
print('Error cuadratico medio:', metrics.mean_squared_error(y_test, y_pred))

# Calcular el R^2
r2 = r2_score(y_test, y_pred)
# Imprimir el R^2
print('Coeficiente de determinación R^2:', r2)

# Calcular la media de y_test
y_mean = np.mean(y_test)

# Calcular el total de la suma de los cuadrados (TSS)
TSS = np.sum((y_test - y_mean) ** 2)

# Calcular el total de la suma de los cuadrados residuales (RSS)
RSS = np.sum((y_test - y_pred) ** 2)

# Calcular R^2
r2 = 1 - (RSS/TSS)

print('r2 prueba:', r2)

#Imprimir coeficientes
print('Coeficientes: ', regressor.coef_)
#Imprimir intercepto
print('Intercepto: ', regressor.intercept_)
#Imprimir ecuacion de la recta
print('Ecuacion de la recta en forma matricial: y= ', regressor.coef_, 'x +', regressor.intercept_)

#Grafica de predicciones
import matplotlib.pyplot as plt

# Crear una figura
plt.figure(figsize=(10,6))

# Crear un gráfico de línea con los datos reales
plt.plot(range(len(y_test)), y_test, color = 'red', label = 'Real')

# Crear un gráfico de línea con las predicciones
plt.plot(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicción')

# Añadir títulos y etiquetas
plt.title('Comparación de los valores reales y las predicciones')
plt.xlabel('Índice')
plt.ylabel('Precio')
plt.legend()

# Mostrar la gráfica
plt.show()

```

Ejemplo de regresión lineal en R:
```{r}
datos_r <- read.csv('datos_Media_Diario_Climatico_Demanda_Estructura.csv', sep=';')

names(datos_r)

#pairs(datos_r)

#cor(x = datos_r, method = "pearson")

library(psych)
multi.hist(x = datos_r, dcol = c("blue", "red"), dlty = c("dotted", "solid"),
           main = "")


modelo <- lm(Precio ~ Año + Mes + Dia + tmed +
               prec + tmin + tmax + Demanda + Hidráulica + Turbinación.bombeo + Nuclear + Carbón + Fuel...Gas 
               + Motores.diésel + Turbina.de.gas + Turbina.de.vapor + Ciclo.combinado + Hidroeólica + Eólica + Solar.fotovoltaica
                + Solar.térmica + Otras.renovables + Cogeneración + Residuos.no.renovables + Residuos.renovables + Generación.total
               , data = datos_r )
summary(modelo)

step(object = modelo, direction = "both", trace = 1)

modelo_Corregido <- lm(formula = Precio ~ Mes + tmin + Hidráulica + Turbinación.bombeo + 
    Nuclear + Motores.diésel + Turbina.de.vapor + Hidroeólica + 
    Eólica + Solar.térmica + Residuos.no.renovables + Generación.total + 
    Cogeneración, data = datos_r)

summary(modelo_Corregido)
```

Regresión de Ridge
```{python}
print('Modelo de regresion de Ridge')

from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split

#separar datos de entrenamiento y de prueba por el 80% y 20%
X = datos.iloc[:, :-1].values

#datos de la columna precio es la utlima columna
y = datos.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)

#entrenar el modelo
ridgeReg = Ridge(alpha=0.05)

ridgeReg.fit(X_train,y_train)

#predecir los resultados
y_pred = ridgeReg.predict(X_test)

#comparar los resultados
df = pd.DataFrame({'Real': y_test, 'Prediccion': y_pred})

print(df)

#error cuadratico medio
from sklearn import metrics
print('Error cuadratico medio:', metrics.mean_squared_error(y_test, y_pred))

# Calcular el R^2
r2 = ridgeReg.score(X_test, y_test)
# Imprimir el R^2
print('Coeficiente de determinación R^2:', r2)

#Grafica de predicciones
import matplotlib.pyplot as plt

# Crear una figura
plt.figure(figsize=(10,6))

# Crear un gráfico de línea con los datos reales
plt.plot(range(len(y_test)), y_test, color = 'red', label = 'Real')

# Crear un gráfico de línea con las predicciones
plt.plot(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicción')

# Añadir títulos y etiquetas
plt.title('Comparación de los valores reales y las predicciones')
plt.xlabel('Índice')
plt.ylabel('Precio')
plt.legend()

# Mostrar la gráfica
plt.show()

```

Regresión Bayesiana
```{python}
print('Modelo de regresion Bayesiana')

from sklearn.linear_model import BayesianRidge
from sklearn.model_selection import train_test_split

#separar datos de entrenamiento y de prueba por el 80% y 20%
X = datos.iloc[:, :-1].values

#datos de la columna precio es la utlima columna
y = datos.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)

#entrenar el modelo
bayesianRidge = BayesianRidge()

bayesianRidge.fit(X_train,y_train)

#predecir los resultados
y_pred = bayesianRidge.predict(X_test)

#comparar los resultados
df = pd.DataFrame({'Real': y_test, 'Prediccion': y_pred})

print(df)

#error cuadratico medio
from sklearn import metrics

#pasar y_pred de arraylike a numpy array
y_pred = np.asarray(y_pred)

print('Error cuadratico medio:', metrics.mean_squared_error(y_test, y_pred))

# Calcular el R^2
r2 = bayesianRidge.score(X_test, y_test)
# Imprimir el R^2
print('Coeficiente de determinación R^2:', r2)

#Grafica de predicciones
import matplotlib.pyplot as plt

# Crear una figura
plt.figure(figsize=(10,6))

# Crear un gráfico de línea con los datos reales
plt.plot(range(len(y_test)), y_test, color = 'red', label = 'Real')

# Crear un gráfico de línea con las predicciones
plt.plot(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicción')

# Añadir títulos y etiquetas
plt.title('Comparación de los valores reales y las predicciones')
plt.xlabel('Índice')
plt.ylabel('Precio')
plt.legend()

# Mostrar la gráfica
plt.show()


```

Proceso Gaussiano
```{python}
print('Modelo de proceso Gaussiano')

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
from sklearn.model_selection import train_test_split

#separar datos de entrenamiento y de prueba por el 80% y 20%
X = datos.iloc[:, :-1].values

#datos de la columna precio es la utlima columna
y = datos.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)

#entrenar el modelo
kernel = DotProduct() + WhiteKernel()
gaussianProcess = GaussianProcessRegressor(kernel=kernel, random_state=0)

gaussianProcess.fit(X_train,y_train)

#predecir los resultados
y_pred = gaussianProcess.predict(X_test)

#comparar los resultados
df = pd.DataFrame({'Real': y_test, 'Prediccion': y_pred})

print(df)

#Error cuadratico medio
from sklearn import metrics
print('Error cuadratico medio:', metrics.mean_squared_error(y_test, y_pred))

# Calcular el R^2
r2 = gaussianProcess.score(X_test, y_test)
# Imprimir el R^2
print('Coeficiente de determinación R^2:', r2)

#Grafica de predicciones
import matplotlib.pyplot as plt

# Crear una figura
plt.figure(figsize=(10,6))

# Crear un gráfico de línea con los datos reales
plt.plot(range(len(y_test)), y_test, color = 'red', label = 'Real')

# Crear un gráfico de línea con las predicciones
plt.plot(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicción')

# Añadir títulos y etiquetas
plt.title('Comparación de los valores reales y las predicciones')
plt.xlabel('Índice')
plt.ylabel('Precio')
plt.legend()

# Mostrar la gráfica
plt.show()


```
Regresión Polinomial en R:
```{r}
# Cargar el paquete glmnet
library(Matrix)
library(glmnet)

# Asumiendo que tus datos están en un data.frame llamado datos_r y Precio es tu variable dependiente
# Primero, debes convertir tus variables independientes a una matriz
x <- model.matrix(Precio ~ ., datos_r)[,-1]

# Luego, convierte tu variable dependiente a un vector
y <- datos_r$Precio

# Ajustar el modelo de regresión de Ridge utilizando validación cruzada para encontrar el mejor valor de lambda
modelo_ridge <- cv.glmnet(x, y, alpha = 0)

# Imprimir un resumen del modelo
print(modelo_ridge)

# Para obtener los coeficientes del modelo en el valor óptimo de lambda
coef(modelo_ridge, s = modelo_ridge$lambda.min)
```

Graficos con R:
```{r}
# Cargar la librería necesaria
library(ggplot2)
library(reshape2)


# Crear una nueva columna "fecha" combinando año, mes y día
datos_r$fecha <- as.Date(paste(datos_r$Año, datos_r$Mes, datos_r$Dia, sep="-"), format="%Y-%m-%d")

# Crear el gráfico
ggplot(data=datos_r, aes(x=fecha, y=Precio)) +
    geom_line() +
    labs(title="Evolución del precio a lo largo del año 2019",
         x="Fecha",
         y="Precio")

# Cambiar el formato del dataframe de ancho a largo
dataframe_largo <- melt(datos_r, 
                        measure.vars = c("Hidráulica", "Turbinación.bombeo", "Nuclear", 
                                         "Carbón", "Fuel...Gas", "Motores.diésel", 
                                         "Turbina.de.gas", "Turbina.de.vapor", 
                                         "Ciclo.combinado", "Hidroeólica", "Eólica", 
                                         "Solar.fotovoltaica", "Solar.térmica", 
                                         "Otras.renovables", "Cogeneración", 
                                         "Residuos.no.renovables", "Residuos.renovables"))

# Calcular la suma total para cada tipo de generación de energía
sumas <- aggregate(value ~ variable, dataframe_largo, sum)

# Crear el gráfico de barras
ggplot(data = sumas, aes(x = variable, y = value, fill = variable)) +
  geom_bar(stat = "identity") +
  labs(x = "Tipo de generación", y = "Cantidad total", fill = "Tipo de generación") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Cambiar el formato del dataframe de ancho a largo
dataframe_largo <- melt(datos_r, id.vars = "fecha", 
                        measure.vars = c("Hidráulica", "Turbinación.bombeo", "Nuclear", 
                                         "Carbón", "Fuel...Gas", "Motores.diésel", 
                                         "Turbina.de.gas", "Turbina.de.vapor", 
                                         "Ciclo.combinado", "Hidroeólica", "Eólica", 
                                         "Solar.fotovoltaica", "Solar.térmica", 
                                         "Otras.renovables", "Cogeneración", 
                                         "Residuos.no.renovables", "Residuos.renovables"))

# Crear el gráfico de líneas
ggplot(data = dataframe_largo, aes(x = fecha, y = value, color = variable)) +
  geom_line() +
  labs(x = "Fecha", y = "Cantidad", color = "Tipo de generación") +
  theme_minimal()

# Crear el gráfico de líneas
ggplot(data = datos_r, aes(x = fecha, y = Demanda)) +
  geom_line() +
  labs(x = "Fecha", y = "Demanda") +
  theme_minimal()


# Crear un gráfico de líneas
ggplot(datos_r, aes(x = fecha)) + 
  geom_line(aes(y = Generación.total, color = "Generación total")) + 
  geom_line(aes(y = Demanda, color = "Demanda")) +
  labs(x = "Fecha", y = "Valor", color = "Variable") +
  ggtitle("Comparación de la Generación Total y la Demanda")


# Crear un gráfico de líneas
ggplot(datos_r, aes(x = fecha)) + 
  geom_line(aes(y = Residuos.no.renovables, color = "Residuios no renovables")) +
  geom_line(aes(y = Residuos.renovables, color = "Residuos renovables")) +
  labs(x = "Fecha", y = "Valor", color = "Variable") +
  ggtitle("Comparación de los residuos")



```


```{python}
# Importar las bibliotecas necesarias
import pandas as pd
import matplotlib.pyplot as plt

# Asumiendo que tus datos están en un DataFrame de pandas llamado datos_r
# Calcular los totales de cada columna
totales = datos[["Hidráulica", "Turbinación bombeo", "Nuclear", 
                   "Carbón", "Fuel + Gas", "Motores diésel", 
                   "Turbina de gas", "Turbina de vapor", 
                   "Ciclo combinado", "Hidroeólica", "Eólica", 
                   "Solar fotovoltaica", "Solar térmica", 
                   "Otras renovables", "Cogeneración", 
                   "Residuos no renovables", "Residuos renovables"]].sum()

# Crear un gráfico de barras de los totales
plt.bar(totales.index, totales.values)
plt.title("Total de Generación por Fuente")
plt.ylabel("Total")
plt.xlabel("Fuente")
plt.xticks(rotation=90)
plt.show()

```
Red Neuronal:
```{python}

#---------------------------------------------------------------------------------------------Modelo de redes neuronales

#Modelo de redes neuronales con funcion de activacion Sigmoide
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense
from sklearn import metrics

# crear modelo de red neuronal

# Datos x como variables independientes y y como variable dependiente
#y es la ultima columna
X = datos.iloc[:, :-1].values
#x es todo menos la ultima columna
y = datos.iloc[:, -1].values

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Normalizar los datos
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Crear la red neuronal
model = Sequential()
model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))
model.add(Dense(16, activation='relu'))
model.add(Dense(1))

# Compilar el modelo
model.compile(optimizer='adam', loss='mean_squared_error')

# Entrenar el modelo
model.fit(X_train, y_train, epochs=500, batch_size=32)

# Predecir los precios en el conjunto de prueba
y_pred = model.predict(X_test)

# Comparar los resultados
df = pd.DataFrame({'Real': y_test, 'Prediccion': y_pred.flatten()})
print(df)

# Error cuadratico medio
from sklearn import metrics
print('Error cuadratico medio:', metrics.mean_squared_error(y_test, y_pred))

# R2
print('R2:', metrics.r2_score(y_test, y_pred))

# Calcular el coeficiente de determinación R^2
r2 = metrics.r2_score(y_test, y_pred)

# Imprimir el resultado
print('Coeficiente de determinación R^2:', r2)

#Grafica de predicciones
import matplotlib.pyplot as plt

# Crear una figura
plt.figure(figsize=(10,6))

# Crear un gráfico de línea con los datos reales
plt.plot(range(len(y_test)), y_test, color = 'red', label = 'Real')

# Crear un gráfico de línea con las predicciones
plt.plot(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicción')

# Añadir títulos y etiquetas
plt.title('Comparación de los valores reales y las predicciones')
plt.xlabel('Índice')
plt.ylabel('Precio')
plt.legend()

# Mostrar la gráfica
plt.show()


#---------------------------------------------------------------------------------------------
```


Bibliografía de herramientas:
https://unipython.com/analisis-de-series-temporales-con-la-libreria-pandas/
https://www.cienciadedatos.net/documentos/py10-regresion-lineal-python.html
https://www.cienciadedatos.net/documentos/py06_machine_learning_python_scikitlearn.html
https://github.com/XavierCarrera/Tutorial-Machine-Learning-Regresion-Lineal
https://rpubs.com/Joaquin_AR/226291

https://www.ree.es/es/sala-de-prensa/actualidad/notas-de-prensa/2019/12/espana-cierra-2019-con-un-10-mas-de-potencia-instalada-de-generacion-renovable
https://www.ine.es/prodyser/espa_cifras/2019/40/
